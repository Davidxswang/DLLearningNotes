{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Note_2_TensorFlow_Keras_Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnTwwYhhdGdtbx2YKq3MIN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davidxswang/ML/blob/master/Note_2_TensorFlow_Keras_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_-WhUvdn0jG",
        "colab_type": "text"
      },
      "source": [
        "# A easy demo provided by TensorFlow tutorial\n",
        "\n",
        "## Import the packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJvNhympnxRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def println(*arg, **argm):\n",
        "  print(*arg, **argm)\n",
        "  print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeAUObr_oC4G",
        "colab_type": "code",
        "outputId": "d4200326-04eb-4695-a234-c54bebd63b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# In note 1, we import the data from TensorFlow Datasets. In this notebook, MNIST dataset is imported from tensorflow.keras\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# Let's see what type mnist is and what methods it has\n",
        "println('Class of mnist: ', type(mnist))\n",
        "println('Methods: ', dir(mnist))\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Let's take a look at the x and y data\n",
        "println('Type of X:', type(x_train),'Type of Y:', type(y_train))\n",
        "println('Shape of train data X and Y:', x_train.shape, y_train.shape)\n",
        "println('Shape of test data X and Y:', x_test.shape, y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class of mnist:  <class 'module'>\n",
            "\n",
            "\n",
            "Methods:  ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_sys', 'load_data']\n",
            "\n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Type of X: <class 'numpy.ndarray'> Type of Y: <class 'numpy.ndarray'>\n",
            "\n",
            "\n",
            "Shape of train data X and Y: (60000, 28, 28) (60000,)\n",
            "\n",
            "\n",
            "Shape of test data X and Y: (10000, 28, 28) (10000,)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyav5H6fpy-Y",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "136M5__HpxH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLR0FMpPqA2l",
        "colab_type": "text"
      },
      "source": [
        "## Build a simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh8SIMO3odB9",
        "colab_type": "code",
        "outputId": "250c9f1e-5cb4-420b-d9d9-135e8a775ca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Using a sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8YoEDTCqhVM",
        "colab_type": "code",
        "outputId": "d27a8a4e-d0ba-4c71-fb1c-b8c8a0e7aad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# Model can be used directly to make predictions\n",
        "predictions = model(x_train[:5])\n",
        "println('Type of model output:',type(predictions))\n",
        "# Make the eager tensor a numpy array\n",
        "predictions = predictions.numpy()\n",
        "println('Shape of output:', predictions.shape)\n",
        "# Predictions in logits\n",
        "println('Predictions in logits:\\n',predictions)\n",
        "\n",
        "# We can convert it to softmax\n",
        "softmax = tf.math.softmax(predictions)\n",
        "println('Softmax scores:\\n', softmax.numpy())\n",
        "\n",
        "# To extract the final answer, use argmax\n",
        "answers = tf.math.argmax(softmax)\n",
        "println('answers:\\n', answers.numpy())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of model output: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "\n",
            "\n",
            "Shape of output: (5, 10)\n",
            "\n",
            "\n",
            "Predictions in logits:\n",
            " [[-0.00230959  0.2214871  -0.4115647   0.2289016   0.26367307 -0.03993828\n",
            "   0.64832723  0.43176267  0.3787859  -0.5045202 ]\n",
            " [-0.07647131  0.65674615 -0.44338775 -0.38423407  0.6609993  -0.27736318\n",
            "   0.6365055   0.30101457 -0.00919661 -0.3983376 ]\n",
            " [ 0.00448105  0.2176928  -0.2755806  -0.42820334  0.32588345 -0.31509233\n",
            "   0.23399732  0.30821893  0.19844379 -0.1295808 ]\n",
            " [ 0.12579493  0.07337835 -0.09894928  0.0238513  -0.00281115  0.18687044\n",
            "   0.51239896  0.07370916 -0.07527938 -0.6443805 ]\n",
            " [-0.7268912   0.5398196  -0.5318779  -0.29351652 -0.34794202  0.02278585\n",
            "   0.18510334 -0.11922857 -0.14946903  0.31888437]]\n",
            "\n",
            "\n",
            "Softmax scores:\n",
            " [[0.08352656 0.10447641 0.05547373 0.10525393 0.10897814 0.08044197\n",
            "  0.16010046 0.12892579 0.12227347 0.05054956]\n",
            " [0.07866941 0.16377147 0.05450749 0.05782908 0.1644695  0.06435166\n",
            "  0.16048995 0.11474822 0.08414396 0.05701921]\n",
            " [0.09570147 0.11844461 0.07232516 0.06208779 0.13197811 0.06952319\n",
            "  0.12039162 0.12966725 0.11618647 0.08369438]\n",
            " [0.10758427 0.10209031 0.08592977 0.09715725 0.09460104 0.11435983\n",
            "  0.1583612  0.10212409 0.08798798 0.04980418]\n",
            " [0.0504122  0.17892094 0.06126732 0.07775851 0.07363956 0.10668817\n",
            "  0.12549022 0.09256359 0.08980633 0.1434532 ]]\n",
            "\n",
            "\n",
            "answers:\n",
            " [3 4 3 0 1 3 1 2 0 4]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crhcgQkTq28b",
        "colab_type": "code",
        "outputId": "b723088b-ecb6-4974-d344-500ad8d94402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# We can calculate the loss by compare softmax with y, or by compare logits with y\n",
        "# Logits with y\n",
        "sparselogitloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_1 = sparselogitloss(y_train[:5], predictions).numpy()\n",
        "println('Loss calculated by logits and y:',loss_1)\n",
        "\n",
        "# softmax with y\n",
        "sparsesoftmaxloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "loss_2 = sparsesoftmaxloss(y_train[:5], softmax).numpy()\n",
        "println('Loss calculated by softmax and y:', loss_2)\n",
        "\n",
        "# This type of loss should be negative log possibility\n",
        "loss_3_guess = -tf.math.log(1/10).numpy()\n",
        "println('If we guess, the loss should be:', loss_3_guess)\n",
        "# So it's very close to guess randomly when the network is not trained at all"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss calculated by logits and y: 2.2622967\n",
            "\n",
            "\n",
            "Loss calculated by softmax and y: 2.262297\n",
            "\n",
            "\n",
            "If we guess, the loss should be: 2.3025851\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN_kXDCzvZxq",
        "colab_type": "code",
        "outputId": "31a1415f-0a9f-4f39-8d19-3dc97ab6d68c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# designate the optimizer, loss function and metrics\n",
        "model.compile(optimizer='adam', loss=sparselogitloss, metrics='acc')\n",
        "\n",
        "# train the network\n",
        "# default batch_size is 32 (batch_size=None)\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=60000)\n",
        "\n",
        "# let's take a look at history\n",
        "println('Type of history:',history)\n",
        "println('Method of history:', dir(history))\n",
        "println('Commonly used history:', type(history.history),'keys of dict:',list(history.history.keys()))\n",
        "println('Type of loss and acc:', type(history.history['loss']),type(history.history['acc']))\n",
        "println('Type of epoch:', type(history.epoch))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3715 - acc: 0.1153\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2036 - acc: 0.2068\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0616 - acc: 0.3237\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9389 - acc: 0.4152\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8238 - acc: 0.4913\n",
            "Type of history: <tensorflow.python.keras.callbacks.History object at 0x7fdba0785b00>\n",
            "\n",
            "\n",
            "Method of history: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_chief_worker_only', '_implements_predict_batch_hooks', '_implements_test_batch_hooks', '_implements_train_batch_hooks', '_keras_api_names', '_keras_api_names_v1', 'epoch', 'history', 'model', 'on_batch_begin', 'on_batch_end', 'on_epoch_begin', 'on_epoch_end', 'on_predict_batch_begin', 'on_predict_batch_end', 'on_predict_begin', 'on_predict_end', 'on_test_batch_begin', 'on_test_batch_end', 'on_test_begin', 'on_test_end', 'on_train_batch_begin', 'on_train_batch_end', 'on_train_begin', 'on_train_end', 'params', 'set_model', 'set_params', 'validation_data']\n",
            "\n",
            "\n",
            "Commonly used history: <class 'dict'> keys of dict: ['loss', 'acc']\n",
            "\n",
            "\n",
            "Type of loss and acc: <class 'list'> <class 'list'>\n",
            "\n",
            "\n",
            "Type of epoch: <class 'list'>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUjBRPP-xESy",
        "colab_type": "code",
        "outputId": "c1ee1310-eca1-439e-b6c8-29fea66ed93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "evaluate = model.evaluate(x_test, y_test)\n",
        "println('Type of evaluate:', type(evaluate), 'content:', evaluate)\n",
        "loss, acc = evaluate\n",
        "println(f'Loss is: {loss}, accuracy is: {acc}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 1.6871 - acc: 0.6169\n",
            "Type of evaluate: <class 'list'> content: [1.6870594024658203, 0.6169000267982483]\n",
            "\n",
            "\n",
            "Loss is: 1.6870594024658203, accuracy is: 0.6169000267982483\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ8ej9gy3LJM",
        "colab_type": "text"
      },
      "source": [
        "## A harder demo provided by TensorFlow tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3v9ImLP2f8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t17nVjBM3ZzN",
        "colab_type": "code",
        "outputId": "d1a5e7c1-afe9-46c4-d483-ca9e5c9c01a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# We will continue using mnist dataset\n",
        "# But as we can see the mnist dataset Keras provides doesn't have a channel dimension, we need to add one at the tail\n",
        "x_train = tf.expand_dims(x_train, -1)\n",
        "x_test = tf.expand_dims(x_test, -1)\n",
        "println(f'Shape of x_train is {x_train.shape}, shape of x_test is {x_test.shape}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train is (60000, 28, 28, 1), shape of x_test is (10000, 28, 28, 1)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZeYjz_43aWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cfdf07d2-c3b2-4984-f8c2-b68fe4b69542"
      },
      "source": [
        "# from_tensor_slices can take slice in tuple or dictionary, and make every slice an element of the dataset.\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).batch(60000)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(10000)\n",
        "for example in train_ds.take(1):\n",
        "  println(f'this example is a {type(example)}, first element is a {type(example[0])}, second element is a {type(example[1])}')\n",
        "  println(f'shape of first element is {example[0].shape}, shape of second element is {example[1].shape}')\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this example is a <class 'tuple'>, first element is a <class 'tensorflow.python.framework.ops.EagerTensor'>, second element is a <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "\n",
            "\n",
            "shape of first element is (60000, 28, 28, 1), shape of second element is (60000,)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfTiwJLMienF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is another extremity here, to subclass the Keras model. This is not used commonly, but good to know.\n",
        "# This regime is to separate the definition part and the call part.\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  # call is used in forward pass, both in training and inference.\n",
        "  # We can pass a training argument to call, so that we can let it behave differently in training and inference time.\n",
        "  # x is the input of the model\n",
        "  def call(self, x, training=False):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model_1 = MyModel()\n",
        "\n",
        "\n",
        "# This is \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}