{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Note_1_TensorFlow_Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11ufOmfkev7Dgrcih1gnE_dkzqdG-IV_9",
      "authorship_tag": "ABX9TyPdTSupJDskZcNZ2+vZiq5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davidxswang/ML/blob/master/Note_1_TensorFlow_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNBJth7oyPKb",
        "colab_type": "text"
      },
      "source": [
        "# Import the packages and check the environment\n",
        "[Refer to the link for full tutorial](https://www.tensorflow.org/datasets/overview)\n",
        "\n",
        "**Be careful, in the tutorial, two lines of code cannot work:**\n",
        "- **fig = tfds.show_examples(ds, info)**\n",
        "- **print(info.splits['train'].filenames)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wer7IfYTQEC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY3vNJhTZy4b",
        "colab_type": "code",
        "outputId": "e7678c44-4feb-4b14-8478-150aef081536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pwd\n",
        "# mnist dataset is stored in the path below\n",
        "#! mkdir /content/drive/My\\ Drive/colab/mnist"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFEpOR6Eybfd",
        "colab_type": "text"
      },
      "source": [
        "# How to use tfds\n",
        "\n",
        "## See what datasets are included in the tfds\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NDidZVSY-2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To see what datasets are available (included in tfds)\n",
        "if False:\n",
        "  tfds.list_builders()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-FqIFiyqGH",
        "colab_type": "text"
      },
      "source": [
        "## How to load the dataset, what type of structure the data has\n",
        "\n",
        "There are three key things you need to know:\n",
        "1. as_supervised argument of load method\n",
        "2. batch_size argument of load method\n",
        "3. as_numpy() method of tdfs\n",
        "\n",
        "The 1 and 2 will affect the output structure of the load method.\n",
        "\n",
        "The 3 can convert the tf.data.Dataset into Generator[np.ndarray] and tf.Tensor into np.ndarray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wc1sk2PTOBM",
        "colab_type": "code",
        "outputId": "b072e9c5-c3b7-4545-d2a8-17de9d760be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# all the configs\n",
        "as_supervised = True\n",
        "# if True, elements in ds_train are tuple, if False, elements are dict\n",
        "\n",
        "batch_size = None\n",
        "# -1, load the full batch into a tuple/dict, ds_train will be a tuple if used with as_supervised=True, a dict if as_supervised=False\n",
        "# None, ds_train will be tf.data.Dataset, no matter what as_supervised is\n",
        "\n",
        "\n",
        "# load the data\n",
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=as_supervised,     \n",
        "    with_info=True,\n",
        "    data_dir='/content/drive/My Drive/colab/mnist',\n",
        "    batch_size=batch_size\n",
        ")\n",
        "print(ds_info)\n",
        "\n",
        "print('We can access the features of the dataset by this way:')\n",
        "print(ds_info.features.shape, ds_info.features.dtype)\n",
        "print(ds_info.features['image'].shape, ds_info.features['image'].dtype)\n",
        "print(ds_info.features['label'].num_classes, ds_info.features['label'].names, ds_info.features['label'].int2str(7), ds_info.features['label'].str2int('7'))\n",
        "print(\"\\n\")\n",
        "\n",
        "print('We can access the split of the dataset by this way:')\n",
        "print(ds_info.splits)\n",
        "print(list(ds_info.splits.keys()))\n",
        "print(dir(ds_info.splits['train']))\n",
        "print(ds_info.splits['train'].num_examples)\n",
        "print(ds_info.splits['train'].file_instructions)\n",
        "print(ds_info.splits['train'].file_instructions[0]['filename'])\n",
        "print(ds_info.splits['train'].num_shards)\n",
        "print(ds_info.splits['train[15%:25%]'].num_examples)\n",
        "print(ds_info.splits['train[15%:25%]'].file_instructions)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('ds_train type is (tuple, dict or tf.data.Dataset): ', type(ds_train))\n",
        "# take a look at the internal structure of the data\n",
        "if batch_size == -1:\n",
        "  # ds_train will be dict or tuple\n",
        "  if as_supervised:\n",
        "    print('ds_train will be a tuple (images, labels)')\n",
        "    print('How many images in ds_train: ', len(ds_train[0]))\n",
        "    print('Type of elements in ds_train\\'s images: ', type(ds_train[0][0]))\n",
        "    print('Shape of the image: ', ds_train[0][0].shape)\n",
        "    print('Type of elements in ds_train\\'s labels: ', type(ds_train[1][0]))\n",
        "    print('The value of the label: ', ds_train[1][0].numpy())\n",
        "    print('\\n')\n",
        "    print('We can use tfds.as_numpy(something) to convert something into: Generator[np.ndarray] from tf.data.Dataset, or np.ndarray from tf.Tensor')\n",
        "    print('We can convert ds_train[0] which is originally a tf.Tensor, now the type is: ', type(tfds.as_numpy(ds_train[0])))\n",
        "    print('We can also convert the ds_train (a tuple) directly, after convert it\\'s still a', type(tfds.as_numpy(ds_train)), ', the ds_train[0] is now the type of: ', type(tfds.as_numpy(ds_train)[0]))\n",
        "  else:\n",
        "    print('ds_train will be a dict {\\'image\\': image, \\'label\\': label}')\n",
        "    print('Type of ds_train[\\'image\\']: ', type(ds_train['image']))\n",
        "    print('Shape of ds_train[\"image\"]: ', ds_train['image'].shape)\n",
        "    print('Type of ds_train[\\'label\\']: ', type(ds_train['label']))\n",
        "    print('Shape of ds_train[\"label\"]: ', ds_train['label'].shape)\n",
        "    print('\\n')\n",
        "    print('We can convert ds_train[\"image\"] which is originally a tf.Tensor, now the type is: ', type(tfds.as_numpy(ds_train[\"image\"])))\n",
        "    print('We can also convert the ds_train (a dict) directly, after convert it\\'s still a', type(tfds.as_numpy(ds_train)), ', the ds_train[\"image\"] is now the type of: ', type(tfds.as_numpy(ds_train)[\"image\"]))\n",
        "elif batch_size is None:\n",
        "  print('ds_train is a tf.data.Dataset object')\n",
        "  ds = ds_train.take(1)\n",
        "  for data in ds:\n",
        "    if as_supervised:\n",
        "      print('The element in ds_train is tuple, as you can see: ', type(data))\n",
        "      print('The type of the first element of this tuple: ', type(data[0]))\n",
        "      print('The shape of this image (tf.Tensor): ', data[0].shape)\n",
        "      print('The type of the second element of this tuple: ', type(data[1]))\n",
        "      print('The shape of this label (tf.Tensor): ', data[1].shape)\n",
        "      print('The value of this label (tf.Tensor): ', data[1].numpy())\n",
        "      print('\\n')\n",
        "      print('We can conver the tf.data.Dataset using tfds.as_numpy() method, the type will be: ', type(tfds.as_numpy(ds)))\n",
        "      print('The element from this generator will be the type of tuple: ', type(list(tfds.as_numpy(ds))[0]))\n",
        "      print('The first element (an image) of this tuple will be the type of np.ndarray: ', type(list(tfds.as_numpy(ds))[0][0]))\n",
        "      print('The shape of this image will be: ', list(tfds.as_numpy(ds))[0][0].shape)\n",
        "    else:\n",
        "      print('The element in ds_train is dict, as you can see: ', type(data))\n",
        "      print('The keys are: ', list(data.keys()))\n",
        "      print('The type of the first element of this dict: ', type(data['image']))\n",
        "      print('The shape of this image (tf.Tensor): ', data['image'].shape)\n",
        "      print('The type of the second element of this dict: ', type(data['label']))\n",
        "      print('The shape of this label (tf.Tensor): ', data['label'].shape)\n",
        "      print('The value of this label (tf.Tensor): ', data['label'].numpy())\n",
        "      print('\\n')\n",
        "      print('We can conver the tf.data.Dataset using tfds.as_numpy() method, the type will be: ', type(tfds.as_numpy(ds)))\n",
        "      print('The element from this generator will be the type of dict: ', type(list(tfds.as_numpy(ds))[0]))\n",
        "      print('The image of this dict will be the type of np.ndarray: ', type(list(tfds.as_numpy(ds))[0]['image']))\n",
        "      print('The shape of this image will be: ', list(tfds.as_numpy(ds))[0]['image'].shape)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.0,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n",
            "We can access the features of the dataset by this way:\n",
            "{'image': (28, 28, 1), 'label': ()} {'image': tf.uint8, 'label': tf.int64}\n",
            "(28, 28, 1) <dtype: 'uint8'>\n",
            "10 ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] 7 7\n",
            "\n",
            "\n",
            "We can access the split of the dataset by this way:\n",
            "{'test': <tfds.core.SplitInfo num_examples=10000>, 'train': <tfds.core.SplitInfo num_examples=60000>}\n",
            "['test', 'train']\n",
            "['_ProtoCls__proto', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_dataset_name', 'file_instructions', 'get_proto', 'num_examples']\n",
            "60000\n",
            "[{'filename': 'mnist-train.tfrecord-00000-of-00001', 'skip': 0, 'take': -1}]\n",
            "mnist-train.tfrecord-00000-of-00001\n",
            "10\n",
            "6000\n",
            "[{'filename': 'mnist-train.tfrecord-00000-of-00001', 'skip': 9000, 'take': 6000}]\n",
            "\n",
            "\n",
            "ds_train type is (tuple, dict or tf.data.Dataset):  <class 'tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter'>\n",
            "ds_train is a tf.data.Dataset object\n",
            "The element in ds_train is tuple, as you can see:  <class 'tuple'>\n",
            "The type of the first element of this tuple:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "The shape of this image (tf.Tensor):  (28, 28, 1)\n",
            "The type of the second element of this tuple:  <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "The shape of this label (tf.Tensor):  ()\n",
            "The value of this label (tf.Tensor):  4\n",
            "\n",
            "\n",
            "We can conver the tf.data.Dataset using tfds.as_numpy() method, the type will be:  <class 'generator'>\n",
            "The element from this generator will be the type of tuple:  <class 'tuple'>\n",
            "The first element (an image) of this tuple will be the type of np.ndarray:  <class 'numpy.ndarray'>\n",
            "The shape of this image will be:  (28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtgS8uMhzb5p",
        "colab_type": "text"
      },
      "source": [
        "## How to use the dataset to train a neural network\n",
        "[Refer to the full tutorial](https://www.tensorflow.org/datasets/keras_example)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWUgHpBAzr4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}